{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder  # For preprocessing input data\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:/Users/HP/Desktop/data_CodeCrafters/Data/Master/Mock_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 11 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   transaction_id           1000 non-null   int64 \n",
      " 1   transaction_date         1000 non-null   object\n",
      " 2   transaction_amount       1000 non-null   int64 \n",
      " 3   merchant_category        1000 non-null   object\n",
      " 4   card_type                1000 non-null   object\n",
      " 5   transaction_location     1000 non-null   object\n",
      " 6   cardholder_age           1000 non-null   int64 \n",
      " 7   cardholder_gender        1000 non-null   object\n",
      " 8   transaction_description  1000 non-null   object\n",
      " 9   account_balance          1000 non-null   int64 \n",
      " 10  calander_income          1000 non-null   int64 \n",
      "dtypes: int64(5), object(6)\n",
      "memory usage: 86.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_id = data['transaction_id']\n",
    "    # Define columns to be scaled, excluding 'transaction_id'\n",
    "    \n",
    "#Convert to datetime format\n",
    "data['transaction_date'] = pd.to_datetime(data['transaction_date'],format='%d-%m-%Y')\n",
    "\n",
    "# Extract components\n",
    "data['transaction_year'] = data['transaction_date'].dt.year\n",
    "data['transaction_month'] = data['transaction_date'].dt.month\n",
    "data['transaction_day'] = data['transaction_date'].dt.day\n",
    "\n",
    "# Drop the transaction_date column\n",
    "data = data.drop('transaction_date', axis=1)\n",
    "numerical_cols = [\n",
    "    'transaction_amount', 'cardholder_age', 'account_balance', 'calander_income','transaction_year','transaction_month','transaction_day'\n",
    "]\n",
    "\n",
    "categorical_cols = [\n",
    "    'merchant_category', 'card_type', 'transaction_location', 'cardholder_gender', \n",
    "]\n",
    "\n",
    "# Create a temporary DataFrame for scaling\n",
    "temp_data = data[numerical_cols].copy()\n",
    "\n",
    "scaler = StandardScaler() # Initialize the StandardScaler\n",
    "temp_data = pd.DataFrame(scaler.fit_transform(temp_data), columns=numerical_cols) # Scale numerical columns\n",
    "\n",
    "# Encode categorical columns\n",
    "encoder = LabelEncoder() # Initialize the LabelEncoder\n",
    "for col in categorical_cols:\n",
    "    data[col] = encoder.fit_transform(data[col]) # Encode categorical columns\n",
    "\n",
    "# Rejoin transaction_id and scaled numerical columns\n",
    "data = data.drop(columns=numerical_cols) # Drop original numerical columns\n",
    "data = pd.concat([data, temp_data], axis=1) # Concatenate scaled numerical columns back\n",
    "# data['transaction_id'] = transaction_id # Reassign transaction_id\n",
    "\n",
    "\n",
    "# # Convert text descriptions into numerical features\n",
    "# Initialize the TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=100)\n",
    "\n",
    "# Transform the transaction_description column\n",
    "description_features = tfidf.fit_transform(data['transaction_description'])\n",
    "\n",
    "# Convert to dataframe\n",
    "description_data = pd.DataFrame(description_features.toarray(), columns=tfidf.get_feature_names_out())\n",
    "\n",
    "# Rejoin the data and drop original column\n",
    "data = pd.concat([data, description_data], axis=1)\n",
    "data = data.drop('transaction_description', axis=1, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>merchant_category</th>\n",
       "      <th>card_type</th>\n",
       "      <th>transaction_location</th>\n",
       "      <th>cardholder_gender</th>\n",
       "      <th>transaction_amount</th>\n",
       "      <th>cardholder_age</th>\n",
       "      <th>account_balance</th>\n",
       "      <th>calander_income</th>\n",
       "      <th>transaction_year</th>\n",
       "      <th>...</th>\n",
       "      <th>ultrices</th>\n",
       "      <th>ut</th>\n",
       "      <th>vel</th>\n",
       "      <th>velit</th>\n",
       "      <th>venenatis</th>\n",
       "      <th>vestibulum</th>\n",
       "      <th>vitae</th>\n",
       "      <th>vivamus</th>\n",
       "      <th>volutpat</th>\n",
       "      <th>vulputate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.743856</td>\n",
       "      <td>-1.403021</td>\n",
       "      <td>-0.754383</td>\n",
       "      <td>0.967126</td>\n",
       "      <td>1.439195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.231837</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.308267</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.306674</td>\n",
       "      <td>0.505341</td>\n",
       "      <td>1.534423</td>\n",
       "      <td>-1.156623</td>\n",
       "      <td>-0.444568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999558</td>\n",
       "      <td>0.232718</td>\n",
       "      <td>-1.093191</td>\n",
       "      <td>0.758704</td>\n",
       "      <td>-0.444568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.294438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.616071</td>\n",
       "      <td>-1.471177</td>\n",
       "      <td>-1.841461</td>\n",
       "      <td>-0.735905</td>\n",
       "      <td>-0.444568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.274229</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1.110613</td>\n",
       "      <td>0.709808</td>\n",
       "      <td>-1.654051</td>\n",
       "      <td>-1.101064</td>\n",
       "      <td>1.439195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   transaction_id  merchant_category  card_type  transaction_location  \\\n",
       "0               1                  3          0                     1   \n",
       "1               2                  6          0                     7   \n",
       "2               3                  7          3                     7   \n",
       "3               4                  7          1                     6   \n",
       "4               5                  1          1                     9   \n",
       "\n",
       "   cardholder_gender  transaction_amount  cardholder_age  account_balance  \\\n",
       "0                  2            0.743856       -1.403021        -0.754383   \n",
       "1                  1            1.306674        0.505341         1.534423   \n",
       "2                  0            0.999558        0.232718        -1.093191   \n",
       "3                  0           -1.616071       -1.471177        -1.841461   \n",
       "4                  2            1.110613        0.709808        -1.654051   \n",
       "\n",
       "   calander_income  transaction_year  ...  ultrices        ut  vel  velit  \\\n",
       "0         0.967126          1.439195  ...       0.0  0.231837  0.0    0.0   \n",
       "1        -1.156623         -0.444568  ...       0.0  0.000000  0.0    0.0   \n",
       "2         0.758704         -0.444568  ...       0.0  0.294438  0.0    0.0   \n",
       "3        -0.735905         -0.444568  ...       0.0  0.000000  0.0    0.0   \n",
       "4        -1.101064          1.439195  ...       0.0  0.000000  0.0    0.0   \n",
       "\n",
       "   venenatis  vestibulum  vitae  vivamus  volutpat  vulputate  \n",
       "0        0.0         0.0    0.0      0.0  0.308267        0.0  \n",
       "1        0.0         0.0    0.0      0.0  0.000000        0.0  \n",
       "2        0.0         0.0    0.0      0.0  0.000000        0.0  \n",
       "3        0.0         0.0    0.0      0.0  0.274229        0.0  \n",
       "4        0.0         0.0    0.0      0.0  0.000000        0.0  \n",
       "\n",
       "[5 rows x 112 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print each column name and its type\n",
    "data.columns = data.columns.astype('str')\n",
    "for col in data.columns:\n",
    "#     print(f\"Column name: {col}, Type: {type(col)}\")\n",
    "    if not isinstance(col, str):  # Check if the column name is not a string\n",
    "        print(col)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.any(np.isnan(data))\n",
    "np.any(np.isinf(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = data\n",
    "X_train, X_temp = train_test_split(X, test_size=0.4, random_state=42)  # 60% train, 40% temp\n",
    "X_test, X_temp = train_test_split(X_temp, test_size=0.625, random_state=42)  # 0.25 * 0.4 = 0.45 for test\n",
    "X_val, X_superval= train_test_split(X_temp, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values\n",
    "X_test = X_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, silhouette_score\n",
    "def perform_hyperparameter_tuning(X_train):\n",
    "    # Define the grid of hyperparameters to search over\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 50, 70],  # Number of base estimators in ensemble\n",
    "        'max_samples': [0.1, 0.05, 0.75],  # Maximum number of samples to draw from the dataset\n",
    "        'max_features':[0.05,0.5,0.7], #Number of Features to draw from dataset to train each base estimator\n",
    "        'contamination': [0.01, 0.05, 0.02],  # Proportion of outliers in the sample\n",
    "        'bootstrap': [True, False]  # Whether bootstrap samples are used when building trees\n",
    "    }\n",
    "    \n",
    "    # Initialize an IsolationForest Ensemble\n",
    "    model = IsolationForest(random_state=42)\n",
    " \n",
    "     # Use a custom scorer, for example, negative mean squared error\n",
    "    def scorer(estimator, X):\n",
    "        cluster_labels = estimator.fit_predict(X)\n",
    "        return silhouette_score(X,cluster_labels)\n",
    "    # scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "    \n",
    "    # Initialize a GridSearchCV to search for the best hyperparameters\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, \n",
    "                               cv=3, n_jobs=-1, verbose=2,scoring=scorer)\n",
    "    \n",
    "    # Fit the GridSearchCV to the training data\n",
    "    grid_search.fit(X_train)\n",
    "    \n",
    "    # Retrieve the best model with the optimal hyperparameters\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Print the best hyperparameters found\n",
    "    print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "    \n",
    "    # Return the best model\n",
    "    return best_model, grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 162 candidates, totalling 486 fits\n",
      "Best hyperparameters: {'bootstrap': False, 'contamination': 0.01, 'max_features': 0.7, 'max_samples': 0.05, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "best_model, best_params = perform_hyperparameter_tuning(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IsolationForest(contamination=0.01, max_features=0.7, max_samples=0.05,\n",
       "                random_state=42)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in pred: {1, -1}\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique labels in pred:\", set(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import davies_bouldin_score\n",
    "test_db_index = davies_bouldin_score(X_test, pred)\n",
    "test_sh_index = silhouette_score(X_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.452983544397346\n"
     ]
    }
   ],
   "source": [
    "print(test_db_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28939692910960135\n"
     ]
    }
   ],
   "source": [
    "print(test_sh_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
